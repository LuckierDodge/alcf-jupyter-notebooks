{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from os.path import basename\n",
    "pd.options.display.max_columns = 1200\n",
    "pd.options.display.max_rows = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/autoperf_filtered_1000000ch', header=0).sample(frac=1)\n",
    "df = pd.read_csv('../data/mira_djc_complete/dim_job_composite.csv', header=0).sample(frac=1)\n",
    "\n",
    "# li = []\n",
    "# for filename in glob.glob(\"/home/luckierdodge/repos/jupyter-notebooks/data/autoperf_complete/autoperf-201*.csv\"):\n",
    "#     frame = pd.read_csv(filename, header=0)\n",
    "#     li.append(frame)\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# df.dropna(inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276314, 58)\n",
      "(275309, 58)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = df.zero_execName.value_counts().to_dict()\n",
    "# df_filtered = pd.DataFrame()\n",
    "# for name in counts:\n",
    "#     if counts[name] >= 500:\n",
    "#         df_filtered = df_filtered.append(df[df[\"zero_execName\"] == name])\n",
    "# df = df_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72299\n",
      "33758\n"
     ]
    }
   ],
   "source": [
    "df['EXEC_NAME'] = df['COMMAND'].apply(basename)\n",
    "print(len(df.COMMAND.unique()))\n",
    "print(len(df.EXEC_NAME.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = .8\n",
    "train = df.head(int(len(df.index) * train_size))\n",
    "test = df.tail(int(len(df.index) * (1-train_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"EXEC_NAME\", \"USERNAME\", \"PROJECT_NAME\", \"QUEUE_NAME\"]\n",
    "targets = [\"WALLTIME_SECONDS\"]\n",
    "# targets = [\"zero_numRanks\"]\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "Y_train = train[targets]\n",
    "Y_test = test[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using SciKit Learn (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=True, categories='auto')\n",
    "enc.fit(X_train.values)\n",
    "\n",
    "# One-hot Encode\n",
    "# user_feature = label_encoder.fit_transform(X_train.values)\n",
    "# user_feature = user_feature.reshape(len(train.index), 1)\n",
    "# user_feature = onehot_encoder.fit_transform(X_train.values)\n",
    "\n",
    "# user_feature = label_encoder.fit_transform(X_test.values)\n",
    "# user_feature = user_feature.reshape(len(test.index), 1)\n",
    "# user_feature = onehot_encoder.fit_transform(X_test.values)\n",
    "\n",
    "X_train_one_hot = enc.transform(X_train.values)\n",
    "X_test_one_hot = enc.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train_one_hot, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789298131898288"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_one_hot, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6579.199413220353"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "Y_predict = model.predict(X_test_one_hot)\n",
    "regression_model_mse = metrics.mean_squared_error(Y_predict, Y_test)\n",
    "math.sqrt(regression_model_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0303161]\n"
     ]
    }
   ],
   "source": [
    "print(math.sqrt(regression_model_mse) / (max(Y_test.values) - min(Y_test.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = X_train_one_hot\n",
    "train_targets = Y_train\n",
    "test_examples = X_test_one_hot\n",
    "test_targets = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<275309x35797 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1101236 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchLoader(train_examples, train_targets, batch_size):\n",
    "\n",
    "    dataset_length = train_examples.shape[0]\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < dataset_length:\n",
    "            limit = min(batch_end, dataset_length)\n",
    "            X = train_examples[batch_start:limit]\n",
    "            Y = train_targets[batch_start:limit]\n",
    "\n",
    "            yield (X, Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<32x35797 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 128 stored elements in Compressed Sparse Row format>,\n",
       "         WALLTIME_SECONDS\n",
       " 83839            43200.0\n",
       " 220758            3600.0\n",
       " 72403            43200.0\n",
       " 36116              900.0\n",
       " 271206            3600.0\n",
       " 243521            6600.0\n",
       " 253582           21600.0\n",
       " 30051             5400.0\n",
       " 114684           43200.0\n",
       " 15838              600.0\n",
       " 269505           21600.0\n",
       " 233678           14400.0\n",
       " 240416           21600.0\n",
       " 154505            3600.0\n",
       " 210694            5400.0\n",
       " 115234             900.0\n",
       " 183157            3600.0\n",
       " 218144           21600.0\n",
       " 230695           14400.0\n",
       " 126298            4200.0\n",
       " 248904            3600.0\n",
       " 266295            6000.0\n",
       " 51000             3600.0\n",
       " 158409            3600.0\n",
       " 149521            2400.0\n",
       " 169640            8400.0\n",
       " 249188            5400.0\n",
       " 204130           21600.0\n",
       " 52212             3600.0\n",
       " 239546            1800.0\n",
       " 16327             3600.0\n",
       " 107331           21600.0)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = batchLoader(train_examples, train_targets, 32)\n",
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu', input_shape=(train_examples.shape[1],)))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu',))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu',))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(0.004)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss='mean_squared_error',\n",
    "             metrics=['mean_absolute_error'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 7s 72ms/step - loss: 143789835.5800 - mean_absolute_error: 6747.8184\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 80485378.0200 - mean_absolute_error: 4770.7329\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 71925576.3000 - mean_absolute_error: 4365.8032\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 6s 65ms/step - loss: 67267333.4600 - mean_absolute_error: 4185.5781\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 59788526.5200 - mean_absolute_error: 3947.1753\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 58521405.4200 - mean_absolute_error: 3804.2222\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 53772306.2700 - mean_absolute_error: 3689.3303\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 53119127.6900 - mean_absolute_error: 3683.4360\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 53477368.0900 - mean_absolute_error: 3719.3857\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 48459155.8100 - mean_absolute_error: 3456.5056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c29c89f50>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(train_examples, train_targets, epochs=10)\n",
    "model.fit(batchLoader(train_examples, train_targets, 64), epochs=10, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 16ms/step - loss: 52677844.6050 - mean_absolute_error: 3431.4553\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_abs_err = model.evaluate(batchLoader(test_examples, test_targets, 64), steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531820339626736\n"
     ]
    }
   ],
   "source": [
    "print(test_abs_err / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
